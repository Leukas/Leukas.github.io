---
layout: page
title: About Me
permalink: /about/
---
<img src="https://avatars.githubusercontent.com/u/5771164?v=4" alt="Avatar" style="width:20vw; border-radius:50%; float:left; margin-right:40px; margin-bottom:10px; margin-top:10px;"> 

<!-- #### Work-Related -->
I am currently a post-doc at LMU, researching various topics, including character-level NLP, low-resource pretraining, and machine translation. My most recent work has been on benchmarking LLMs' understanding of the characters in their tokens, which is surprisingly lacking. I believe that although everyone uses BPE and it is quite powerful, it is not the way forward in the long run. 

I am also quite interested in efficiency methods for making training large models more feasible for everyone, not just big tech companies. In that front I've participated in the BabyLM Challenge, both in 2023 and currently in 2024. Humans clearly learn more efficiently from the "training data" we encounter, but on the other hand it takes us years to develop fluency in a language, whereas we are training LLMs in a matter of months. Is there a best of both worlds? That's what I'd like to find out.

Generally speaking, I am interested in the similarities and differences between machine learning and human learning. I believe there is much we can learn and incorporate from our own brains into ML models. For instance, as we sleep, we are consolidating information, reinforcing things we learned that day, finding ways to recycle neural pathways for other purposes, and more. This is all done without direct access to any input, but ML models currently use input from real-world data to learn. How we can incorporate more of the brain's learning strategies into ML models is something I hope we can learn.
<!-- I am currently a PhD student at University of Groningen, researching machine translation, mainly focusing on the lower-resource languages. My work more recently has shifted to an interest in character-level NLP as I strongly believe we should get rid of this unnatural (but admittedly useful) byte-pair encoding.  -->

<!-- Outside of NLP, I have an interest in computer vision and audio processing, especially the more recent multi-modal models which combine the multiple senses we use similtaneously in our day-to-day lives. -->

<!-- I like to look at machine learning problems from a human perspective, that is, how do we humans solve the problem in our brains? What can we do to make these models more human-like? There is a wealth of neuroscience knowledge out there that's just waiting to be ported over to our ML systems.  -->

<!-- For instance, as we sleep, we are consolidating information, reinforcing things we learned that day, finding ways to recycle neural pathways for other purposes, and more. This is all done without direct access to any input, but ML models currently use input from real-world data to learn. How we can incorporate more of the brain's learning strategies into ML models is something I hope we can figure out. -->


<!-- #### Not Work-Related --> 